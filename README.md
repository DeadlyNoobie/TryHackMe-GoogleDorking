# Google Dorking

## Web Crawlers

**In this challenge we learn about the web crawlers and how they keep keywords to know about certain websites**

**Like using for index the pages while actually the basis of indexing is rather more complex the basic ideas follow up from this.**

Name the key term of what a "Crawler" is used to do

```
index
```

What is the name of the technique that "Search Engines" use to retrieve this information about websites?

```
crawling
```

What is an example of the type of contents that could be gathered from a website?

```
keywords
```

## SEO

**As told over here we see that this matters how websites are responsive and many more factors affects the rank of the website so, it is always beeter to have a good score.**

**Also some of the things within our site which are not supposed to be accessible to everyone through google search.**


## Robots.txt

**This thing has special significance to people like us very frequently in web ctfs we see this thing being mentioned.**

**Go through the entire paragraphs and also visit the site**

[regex](https://www.rexegg.com/regex-quickstart.html)

**The use of regex is very effective as we dive deep into EH**

*Below all questions are from the above given information so read it carefully*

Where would "robots.txt" be located on the domain "ablog.com"

```
ablog.com/robots.txt
```

If a website was to have a sitemap, where would that be located?

```
/sitemap.xml
```

 How would we only allow "Bingbot" to index the website? 

 ```
 User-Agent:Bingbot
 ```

How would we prevent a "Crawler" from indexing the directory "/dont-index-me/"?

```
Disallow:/dont-index-me/
```



What is the extension of a Unix/Linux system configuration file that we might want to hide from "Crawlers"?

```
.conf
```

To see the explanation google it.

## Sitemaps

All the solutions are within the infromation available in the room itself still you can go throgh.

[sitemap](https://yoast.com/what-is-an-xml-sitemap-and-why-should-you-have-one/)

What is the typical file structure of a "Sitemap"?

```
XML
```

What real life example can "Sitemaps" be compared to?

```
map
```

Name the keyword for the path taken for content on a website

```
route
```

## Google Dorking

**Now we come to the main content and we now see that how can we use google to search such good stuff and search it exactly with the use of some very good techniques for our advantage.**

What would be the format used to query the site bbc.co.uk about flood defences

```
site:bbc.co.uk flood defences
```

What term would you use to search by file type?

```
filetype
```

What term can we use to look for login pages?

```
intitle:login
```

**In order to use google dorking read more from google itself as this will help you locate the resources**

[Exploit-DB](https://www.exploit-db.com/google-hacking-database)


**Be aware while using this kind of resources always read the rules of legislations and every other things that might lead to disasters**
